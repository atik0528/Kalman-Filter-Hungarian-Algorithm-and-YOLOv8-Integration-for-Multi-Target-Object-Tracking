{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ea42db",
   "metadata": {},
   "source": [
    "# Object Tracking with Kalman Filter and Hungarian Algorithm\n",
    "\n",
    "In this project, we will use the Kalman filter and Hungarian algorithm to track multiple objects in a video. The Kalman filter will help predict the state of each object, while the Hungarian algorithm will associate detections with existing tracked objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a329d",
   "metadata": {},
   "source": [
    "\n",
    "## Cell 1: Install Required Libraries\n",
    "This command installs the required libraries: opencv-python-headless, torch, numpy, and scipy using pip.\n",
    "- opencv-python-headless: A version of OpenCV without GUI functionality.\n",
    "- torch: PyTorch library for tensor operations and deep learning.\n",
    "- numpy: NumPy library for numerical computations.\n",
    "- scipy: SciPy library for scientific and technical computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9f1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless torch numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a568dbb",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries\n",
    "\n",
    "In this section, we import the necessary libraries for the project. This includes OpenCV for image processing, Torch for building and running the Kalman filter, and Numpy and Scipy for numerical operations.\n",
    "\n",
    "- `cv2` for OpenCV functions to handle image and video processing.\n",
    "- `torch` for using PyTorch functionalities, especially for matrix operations and deep learning.\n",
    "- `np` for NumPy to handle array operations.\n",
    "- `linear_sum_assignment` for solving the assignment problem (used in the Hungarian algorithm).\n",
    "\n",
    "### Theoretical Explanation:\n",
    "\n",
    "1. **OpenCV**: Used for real-time computer vision tasks such as video capture and image processing.\n",
    "2. **PyTorch**: A deep learning framework that provides tensor computation and automatic differentiation.\n",
    "3. **NumPy**: A fundamental package for array operations and numerical computations.\n",
    "4. **SciPy**: Contains modules for optimization, linear algebra, integration, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e2a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec152a8",
   "metadata": {},
   "source": [
    "## Cell 3: TrackerState Class\n",
    "\n",
    "The `TrackerState` class initializes the state transition matrix (F) and measurement matrix (H) for the Kalman filter. These matrices are essential for predicting the next state and updating the state based on measurements.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**State Transition Matrix (F)**: This matrix defines how the state of the system evolves over time. For example, if we know the current position and velocity, we can predict the next position.\n",
    "\n",
    "\\[ F = \\begin{bmatrix} 1 & 0 & \\Delta t & 0 & 0 & 0 \\\\ 0 & 1 & 0 & \\Delta t & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1 \\end{bmatrix} \\]\n",
    "\n",
    "**Measurement Matrix (H)**: This matrix maps the true state space into the observed space. It is used to relate the measurements we get from sensors to the state vector.\n",
    "\n",
    "\\[ H = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1 \\end{bmatrix} \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be508e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackerState(torch.nn.Module):\n",
    "    def __init__(self, dt, device=\"cpu\"):\n",
    "        super(TrackerState, self).__init__()\n",
    "        self.dt = dt\n",
    "        # State transition matrix for position and velocity\n",
    "        self.F = torch.tensor([\n",
    "            [1, 0, self.dt, 0, 0, 0],  # x\n",
    "            [0, 1, 0, self.dt, 0, 0],  # y\n",
    "            [0, 0, 1, 0, 0, 0],        # vx\n",
    "            [0, 0, 0, 1, 0, 0],        # vy\n",
    "            [0, 0, 0, 0, 1, 0],        # w\n",
    "            [0, 0, 0, 0, 0, 1]         # h\n",
    "        ], dtype=torch.float32, device=device)\n",
    "\n",
    "        # Measurement matrix for detecting position\n",
    "        self.H = torch.tensor([\n",
    "            [1, 0, 0, 0, 0, 0],  # x\n",
    "            [0, 1, 0, 0, 0, 0],  # y\n",
    "            [0, 0, 0, 0, 1, 0],  # w\n",
    "            [0, 0, 0, 0, 0, 1]   # h\n",
    "        ], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1155726",
   "metadata": {},
   "source": [
    "## Cell 4: Tracker Class\n",
    "\n",
    "The `Tracker` class represents each object being tracked. It uses the Kalman filter for state prediction and update. The state vector includes position, velocity, width, and height of the bounding box.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**State Vector (x)**: Represents the current state of the object, including its position, velocity, width, and height.\n",
    "\n",
    "\\[ x = \\begin{bmatrix} center_x \\\\ center_y \\\\ v_x \\\\ v_y \\\\ w \\\\ h \\end{bmatrix} \\]\n",
    "\n",
    "**Covariance Matrices (P, Q, R)**:\n",
    "- **P**: Represents the uncertainty in the state estimate.\n",
    "- **Q**: Process noise covariance, models the uncertainty in the process model.\n",
    "- **R**: Measurement noise covariance, models the uncertainty in the measurements.\n",
    "\n",
    "**Kalman Filter Equations**:\n",
    "\n",
    "*Prediction Step*:\n",
    "\\[ x_{k|k-1} = F x_{k-1|k-1} \\]\n",
    "\\[ P_{k|k-1} = F P_{k-1|k-1} F^T + Q \\]\n",
    "\n",
    "*Update Step*:\n",
    "\n",
    "**Innovation**:\n",
    "\\[ y_k = z_k - H x_{k|k-1} \\]\n",
    "\\[ S_k = H P_{k|k-1} H^T + R \\]\n",
    "\n",
    "**Kalman Gain**:\n",
    "\\[ K_k = P_{k|k-1} H^T S_k^{-1} \\]\n",
    "\n",
    "**State Update**:\n",
    "\\[ x_{k|k} = x_{k|k-1} + K_k y_k \\]\n",
    "\n",
    "**Covariance Update**:\n",
    "\\[ P_{k|k} = (I - K_k H) P_{k|k-1} \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6addd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(torch.nn.Module):\n",
    "    def __init__(self, id, box, dt, device=\"cpu\"):\n",
    "        super(Tracker, self).__init__()\n",
    "        self.id = id\n",
    "        self.dt = dt\n",
    "        self.state = TrackerState(dt, device=device)\n",
    "        # State vector: [center_x, center_y, velocity_x, velocity_y, width, height]\n",
    "        self.x_hat = torch.tensor([box[0] + box[2] / 2, box[1] + box[3] / 2, 0, 0, box[2], box[3]], dtype=torch.float32, device=device)\n",
    "        self.P = torch.eye(6, dtype=torch.float32, device=device) * 1000.0  # Initial covariance matrix\n",
    "        self.Q = torch.eye(6, dtype=torch.float32, device=device) * 0.1    # Process noise covariance\n",
    "        self.R = torch.eye(4, dtype=torch.float32, device=device) * 1.0    # Measurement noise covariance\n",
    "\n",
    "    # Predict the next state based on the current state and process model\n",
    "    def predict(self):\n",
    "        self.x_hat = torch.matmul(self.state.F, self.x_hat)  # State prediction\n",
    "        self.P = torch.matmul(torch.matmul(self.state.F, self.P), self.state.F.T) + self.Q  # Covariance prediction\n",
    "\n",
    "    # Update the state based on the measurement\n",
    "    def update(self, z):\n",
    "        S = torch.matmul(torch.matmul(self.state.H, self.P), self.state.H.T) + self.R  # Innovation covariance\n",
    "        K = torch.matmul(torch.matmul(self.P, self.state.H.T), torch.linalg.inv(S))    # Kalman gain\n",
    "        y = z - torch.matmul(self.state.H, self.x_hat)  # Innovation or measurement residual\n",
    "        self.x_hat += torch.matmul(K, y)  # State update\n",
    "        self.P -= torch.matmul(K, torch.matmul(self.state.H, self.P))  # Covariance update\n",
    "\n",
    "    # Get the current state\n",
    "    def get_state(self):\n",
    "        return self.x_hat.clone()\n",
    "\n",
    "    # Get the bounding box from the state vector\n",
    "    def get_bounding_box(self):\n",
    "        x, y, w, h = self.x_hat[0], self.x_hat[1], self.x_hat[4], self.x_hat[5]\n",
    "        return [self.id, int(x - w / 2), int(y - h / 2), int(w), int(h)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bce88",
   "metadata": {},
   "source": [
    "## Cell 5: MultiObjectTracker Class\n",
    "\n",
    "The `MultiObjectTracker` class manages multiple `Tracker` objects. It uses the Hungarian algorithm to match detections to existing trackers and updates their states.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**Multi-Object Tracking**: Involves maintaining a set of objects being tracked across frames.\n",
    "\n",
    "**Assignment Problem**: Solved using the Hungarian algorithm to minimize the total cost of assigning detections to trackers.\n",
    "\n",
    "**Cost Matrix**: Represents the cost (e.g., distance) between each detection and each tracker.\n",
    "\n",
    "**Hungarian Algorithm**: Solves the assignment problem efficiently to find the optimal assignment.\n",
    "\n",
    "**Unmatched Detections and Trackers**:\n",
    "\n",
    "- If a detection does not match any existing tracker, a new tracker is created.\n",
    "- If a tracker does not match any detection, it may be removed or kept based on additional logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977f1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiObjectTracker:\n",
    "    def __init__(self, dt, device=\"cpu\"):\n",
    "        self.trackers = []  # List of trackers\n",
    "        self.next_id = 0    # ID for the next tracker\n",
    "        self.dt = dt\n",
    "        self.device = device\n",
    "\n",
    "    # Update the trackers with new detections\n",
    "    def update(self, detections):\n",
    "        detections_tensor = torch.tensor([[det[0] + det[2] / 2, det[1] + det[3] / 2, det[2], det[3]] for det in detections], dtype=torch.float32, device=self.device)\n",
    "        if not self.trackers:\n",
    "            for det in detections:\n",
    "                self.trackers.append(Tracker(self.next_id, det, self.dt, device=self.device))  # Create new tracker\n",
    "                self.next_id += 1\n",
    "        else:\n",
    "            for tracker in self.trackers:\n",
    "                tracker.predict()  # Predict the next state for each tracker\n",
    "            predicted_positions = torch.stack([tracker.get_state()[:4] for tracker in self.trackers])\n",
    "            cost_matrix = torch.cdist(predicted_positions[:, :2], detections_tensor[:, :2])  # Compute cost matrix\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost_matrix.cpu().numpy())  # Solve assignment problem\n",
    "            unmatched_trackers = set(range(len(self.trackers))) - set(row_ind)\n",
    "            unmatched_detections = set(range(len(detections))) - set(col_ind)\n",
    "\n",
    "            for r, c in zip(row_ind, col_ind):\n",
    "                self.trackers[r].update(detections_tensor[c])  # Update matched trackers\n",
    "            for u in unmatched_detections:\n",
    "                self.trackers.append(Tracker(self.next_id, detections[u], self.dt, device=self.device))  # Create new trackers for unmatched detections\n",
    "                self.next_id += 1\n",
    "            self.trackers = [self.trackers[i] for i in range(len(self.trackers)) if i not in unmatched_trackers]  # Remove unmatched trackers\n",
    "\n",
    "    # Get bounding boxes of all trackers\n",
    "    def get_bounding_boxes(self):\n",
    "        return [tracker.get_bounding_box() for tracker in self.trackers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa6967",
   "metadata": {},
   "source": [
    "## Cell 6: Load YOLO Model\n",
    "\n",
    "This function loads the YOLO model using the given configuration and weights files.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**YOLO (You Only Look Once)**: A real-time object detection system that predicts bounding boxes and class probabilities for objects in a single forward pass of the network.\n",
    "\n",
    "**OpenCV DNN Module**: Provides functions to load and run deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb09b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "def load_yolo_model(model_path, weights_path):\n",
    "    net = cv2.dnn.readNetFromDarknet(model_path, weights_path)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07895ba",
   "metadata": {},
   "source": [
    "## Cell 7: Get Output Layers\n",
    "\n",
    "This function retrieves the names of the output layers of the YOLO model, which are necessary for performing forward passes to get the detections.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**Output Layers**: Layers in the network that produce the final detections (bounding boxes, class probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d948231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output layers of the YOLO model\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ac5b4",
   "metadata": {},
   "source": [
    "## Cell 8: Detect Objects\n",
    "\n",
    "This function uses the YOLO model to detect objects in a given frame. It preprocesses the frame, performs a forward pass, and processes the outputs to extract bounding boxes.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "- **Blob**: A preprocessed image used as input to the neural network.\n",
    "- **Bounding Boxes**: Represent the detected objects' positions and sizes in the image.\n",
    "- **Confidence Score**: The probability that a detected object belongs to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb678e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect objects in the frame using YOLO\n",
    "def detect_objects(frame, net, output_layers):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "    boxes = []\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * frame.shape[1])\n",
    "                center_y = int(detection[1] * frame.shape[0])\n",
    "                w = int(detection[2] * frame.shape[1])\n",
    "                h = int(detection[3] * frame.shape[0])\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04c4a8",
   "metadata": {},
   "source": [
    "## Cell 9: IoU Calculation Function\n",
    "\n",
    "This function calculates the Intersection over Union (IoU) between two bounding boxes. IoU is a measure of the overlap between two bounding boxes, used for evaluating object detection.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**Intersection over Union (IoU)**: A metric used to evaluate the accuracy of an object detector by measuring the overlap between the predicted and ground truth bounding boxes.\n",
    "\n",
    "\\[ IoU = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}} \\]\n",
    "\n",
    "**Intersection Area**: The area where the two bounding boxes overlap.\n",
    "\n",
    "**Union Area**: The total area covered by both bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029bd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Intersection over Union (IoU) between two bounding boxes\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ed1ac",
   "metadata": {},
   "source": [
    "## Cell 10: Main Function\n",
    "\n",
    "The main function orchestrates the entire process. It loads the YOLO model, opens the video file, initializes the multi-object tracker, processes each frame to detect objects, updates trackers, and displays results.\n",
    "\n",
    "### Theoretical and Mathematical Explanation:\n",
    "\n",
    "**YOLO Model**: Used for detecting objects in each frame of the video.\n",
    "\n",
    "**Multi-Object Tracker**: Maintains and updates the state of multiple objects across frames using the Kalman filter and Hungarian algorithm.\n",
    "\n",
    "**OpenCV**: Used for video processing, including reading frames, drawing bounding boxes, and displaying results.\n",
    "\n",
    "**IoU Calculation**: Evaluates the overlap between detected bounding boxes and tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834b4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_path = r\"C:\\Users\\ATIK\\yolov3.cfg\"\n",
    "    weights_path = r\"C:\\Users\\ATIK\\yolov3.weights\"\n",
    "    net = load_yolo_model(model_path, weights_path)  # Load YOLO model\n",
    "    output_layers = get_output_layers(net)  # Get output layers of YOLO model\n",
    "    cap = cv2.VideoCapture(r\"C:\\Users\\ATIK\\video.mp4\")  # Open video file\n",
    "    mot = MultiObjectTracker(1 / 30, device=\"cuda\")  # Initialize multi-object tracker\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Read a frame from the video\n",
    "        if not ret:\n",
    "            break\n",
    "        detections = detect_objects(frame, net, output_layers)  # Detect objects in the frame\n",
    "        detections_tensor = torch.tensor(detections, dtype=torch.float32, device=mot.device)  # Convert detections to tensor\n",
    "        mot.update(detections)  # Update the trackers with new detections\n",
    "        for bbox in mot.get_bounding_boxes():\n",
    "            id, x, y, w, h = bbox\n",
    "            iou = 0.0\n",
    "            if len(detections) > 0:\n",
    "                iou = max(calculate_iou(detections_tensor[i].cpu().numpy(), [x, y, w, h]) for i in range(len(detections)))  # Calculate IoU for each detection\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box\n",
    "            cv2.putText(frame, f'Score: {iou:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Display IoU\n",
    "        cv2.imshow('Frame', frame)  # Show the frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
